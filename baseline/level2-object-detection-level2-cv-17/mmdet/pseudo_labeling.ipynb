{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added annotation num is 23884\n",
      "save on /opt/ml/detection/dataset/test_submission_epoch_20_conf30.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# edited 0404_0320\n",
    "def get_test_annot_from_csv(\n",
    "        base_root, csv_path, test_json_path, save_json_path, conf_thrs, area_min, area_max\n",
    "    ):\n",
    "    # [ps. annot이 존재하지 않는 test image를 json에서 제외하지는 않습니다.]\n",
    "    # csv 파일의 annot을 반영하여 새로운 test json으로 저장하는 함수\n",
    "    \n",
    "    # base_root : 가장 기본이 되는 root\n",
    "    # csv_path : 모델 예측 결과인 csv 파일의 path\n",
    "    # test_json_path : 대회에서 제공된 test json의 path\n",
    "    # save_json_path : annot이 추가된 새로운 test json을 저장하는 path\n",
    "    # conf_thrs : confidence 기준\n",
    "    # area_min, area_max : bbox area 기준 \n",
    "    \n",
    "    df = pd.read_csv(base_root + csv_path)\n",
    "    with open(base_root + test_json_path, 'r') as f:\n",
    "        test_json = json.loads(f.read()) # test json load\n",
    "\n",
    "    annot_cnt = 0 # annot count를 annot_id로 활용\n",
    "    num_image = len(df)\n",
    "    for i in range(num_image):\n",
    "        # df['image_id'][i] : test/0000.jpg\n",
    "        # int : 0000 -> 0 변환\n",
    "        img_id = int(str(df['image_id'][i]).split('/')[-1].split('.')[0])\n",
    "        bbox_info = str(df['PredictionString'][i]).split(' ')[:-1]\n",
    "        \n",
    "        num_bbox = len(bbox_info)//6\n",
    "        if num_bbox != 0: # 이미지 i에 bbox가 존재하면\n",
    "            for bbox_id in range(num_bbox):\n",
    "                # coco format에 필요한 annot 정보\n",
    "                categoryid = int(bbox_info[6*bbox_id+0])\n",
    "                confidence = float(bbox_info[6*bbox_id+1])\n",
    "                x = float(bbox_info[6*bbox_id+2]) # bbox x\n",
    "                y = float(bbox_info[6*bbox_id+3]) # bbox y\n",
    "                w = float(bbox_info[6*bbox_id+4]) - float(bbox_info[6*bbox_id+2]) # bbox width\n",
    "                h = float(bbox_info[6*bbox_id+5]) - float(bbox_info[6*bbox_id+3]) # bbox height\n",
    "                \n",
    "                # bbox가 confidence, bbox area 기준을 충족한다면\n",
    "                if confidence>conf_thrs and area_min<w*h and w*h<area_max:\n",
    "                    annot_dict = dict(\n",
    "                        image_id=img_id,        # image id\n",
    "                        category_id=categoryid, # bbox class\n",
    "                        area=w*h,               # bbox area\n",
    "                        bbox=[x, y, w, h],      # coco format\n",
    "                        iscrowd=0,              # train.josn에서 모두 0\n",
    "                        id=annot_cnt            # annot id\n",
    "                    )\n",
    "                    annot_cnt += 1              # annot count update\n",
    "                    test_json['annotations'].append(annot_dict)\n",
    "    \n",
    "    print(f\"added annotation num is {annot_cnt}\")\n",
    "\n",
    "    # annot 정보를 추가한 test_json을 base_root + save_json_path에 save\n",
    "    with open(base_root + save_json_path, 'w') as f:\n",
    "        json.dump(test_json, f, indent=4)\n",
    "    print(f\"save on {base_root + save_json_path}\")\n",
    "\n",
    "# Example\n",
    "csv_file = 'submission_epoch_20'\n",
    "conf_thrs = 30\n",
    "area_min = 0\n",
    "area_percent_max = 100\n",
    "get_test_annot_from_csv(\n",
    "    base_root='/opt/ml/detection/',\n",
    "    csv_path=f'work_dirs/exp37/Fold3/{csv_file}.csv',\n",
    "    test_json_path='dataset/test.json',\n",
    "    save_json_path=f'dataset/test_{csv_file}_conf{conf_thrs}.json',\n",
    "    conf_thrs=conf_thrs*0.01,\n",
    "    area_min=area_min*0.01,\n",
    "    area_max=area_percent_max*0.01*1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before image num is 3878\n",
      "before annot num is 18398\n",
      "before image-annot ratio is 4.744198040226921\n",
      "after image num is 8749\n",
      "after annot num is 42282\n",
      "after image-annot ratio is 4.832780889244485\n",
      "save on /opt/ml/detection/dataset/stratified_kfold/train_3_test_submission_epoch_20_conf30.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# edited 0404_0320\n",
    "def combine_train_with_pseudo(\n",
    "        base_root, train_json_path, test_json_path, save_json_path\n",
    "    ):\n",
    "    # [ps. pseudo-labeling된 test + train 데이터로 학습하고 싶다면\n",
    "    #      위 함수의 결과로 얻은 test_json을 이 함수에 넣으면 됩니다.]\n",
    "    # 위에서 만든 pseudo-labeling된 test 데이터를 train json에 합치는 함수\n",
    "    \n",
    "    # base_root : 가장 기본이 되는 root\n",
    "    # train_json_path : train json path 또는 cv_train json path (자유)\n",
    "    # test_json_path : pseudo-laebling이 추가된 test json path (중요: 위 함수의 결과)\n",
    "    # save_json_path : test data를 추가한 새로운 train json을 저장하는 path (자유)\n",
    "    \n",
    "    with open(base_root + train_json_path, 'r') as f:\n",
    "        train_json = json.loads(f.read()) # train json load\n",
    "    with open(base_root + test_json_path, 'r') as f:\n",
    "        test_json = json.loads(f.read())  # pseudo-labeling이 추가된 test json load\n",
    "\n",
    "    print(f\"before image num is {len(train_json['images'])}\")\n",
    "    print(f\"before annot num is {len(train_json['annotations'])}\")\n",
    "    print(f\"before image-annot ratio is {len(train_json['annotations'])/len(train_json['images'])}\")\n",
    "\n",
    "    # with_annot : annot이 존재하는 image를 구분하기 위함\n",
    "    with_annot = list(set([annot['image_id'] for annot in test_json['annotations']]))\n",
    "    \n",
    "    for image in test_json['images']:\n",
    "        if image['id'] in with_annot:                        # image가 annot을 포함한다면\n",
    "            save_id = image['id']                            # 추후 비교를 위해 test_json의 image id 저장\n",
    "            image['id'] = train_json['images'][-1]['id'] + 1 # train_json의 마지막 image id에 1을 더함\n",
    "            train_json['images'].append(image)               # train_json의 image list에 test image 추가\n",
    "    \n",
    "            for annot in test_json['annotations']:\n",
    "                if annot['image_id'] == save_id:                          # annot의 image_id가 save_id와 같다면\n",
    "                    annot['image_id'] = train_json['images'][-1]['id']    # train_json의 마지막 image id(앞서 1을 더함)를 annot의 image_id로 update\n",
    "                    annot['id'] = train_json['annotations'][-1]['id'] + 1 # train_json의 마지막 annot id에 1을 더함\n",
    "                    train_json['annotations'].append(annot)               # train_json의 annotations list에 test annotation 추가\n",
    "    \n",
    "    print(f\"after image num is {len(train_json['images'])}\")\n",
    "    print(f\"after annot num is {len(train_json['annotations'])}\")\n",
    "    print(f\"after image-annot ratio is {len(train_json['annotations'])/len(train_json['images'])}\")\n",
    "\n",
    "    # test annot을 추가한 train_json을 base_root + save_json_path에 save\n",
    "    with open(base_root + save_json_path, 'w') as f:\n",
    "        json.dump(train_json, f, indent=4)\n",
    "    print(f\"save on {base_root + save_json_path}\")\n",
    "\n",
    "# Example\n",
    "json_name = f'test_{csv_file}_conf{conf_thrs}' # csv_file, conf_thrs는 위의 cell에서 받아옵니다.\n",
    "combine_train_with_pseudo(\n",
    "    base_root='/opt/ml/detection/',\n",
    "    train_json_path='dataset/stratified_kfold/train_3.json',\n",
    "    test_json_path=f'dataset/{json_name}.json',\n",
    "    save_json_path=f'dataset/stratified_kfold/train_3_{json_name}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b94c6de4bce9a87a354a5fa9998691adc0532adddb9d4140f5ba941d00b01fae"
  },
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
